Prepare for deployment and performance checks

- Verify environment variables for the LLM provider are correctly configured in all environments.
- Run linting and tests.
- Sanity check AI latency and cost (model choice, prompt size) and adjust configuration if needed.

